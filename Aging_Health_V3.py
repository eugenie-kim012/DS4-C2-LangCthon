import os
import streamlit as st
import tiktoken  # í† í° ê³„ì‚° (ì˜ˆ: ê¸¸ì´ ì¸¡ì •)ì— ì‚¬ìš©
import shutil 
import pandas as pd  # CSV íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
from openai import OpenAI
from dotenv import load_dotenv  # .env íŒŒì¼ ë¡œë“œë¥¼ ìœ„í•¨

# ------------ LangChain ì„í¬íŠ¸ ------------------------------
# ê¸°ì¡´ ì„í¬íŠ¸ë“¤ì„ ëª¨ë‘ ì´ë ‡ê²Œ ë³€ê²½í•˜ì„¸ìš”:

# ë²¡í„°ìŠ¤í† ì–´ ê´€ë ¨ 
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI

# ì²´ì¸ ê´€ë ¨ 
from langchain.chains import ConversationalRetrievalChain

# ë¬¸ì„œ ë¡œë”
from langchain_community.document_loaders import PyPDFLoader

# í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„°
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ë©”ëª¨ë¦¬
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

# ë¬¸ì„œ, í”„ë¡¬í”„íŠ¸
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate

# --------------------- API í‚¤ ë° ì´ˆê¸° ì„¤ì • ------------------------------

st.set_page_config(page_title="ğŸ§  OECD Aging and Health ìë£Œ ê²€ìƒ‰ ë´‡", layout="wide")

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# Streamlit ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ ì…ë ¥ë°›ê¸° (.envì—ì„œ ì°¾ìœ¼ë©´ ë¯¸ë¦¬ ì±„ì›Œì§)
st_api_key_input = st.sidebar.text_input("ğŸ”‘ OpenAI API Key", type="password", value=api_key)

# ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©í•  API í‚¤ ê²°ì • (ì‚¬ì´ë“œë°” ì…ë ¥ì´ ìš°ì„ )
openai_api_key = st_api_key_input if st_api_key_input else api_key

# Langchain ë° OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì°¾ë„ë¡ ì„¤ì •
if openai_api_key:
    os.environ["OPENAI_API_KEY"] = openai_api_key
else:
    st.error("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš” (ì‚¬ì´ë“œë°” ë˜ëŠ” .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì •).")
    st.stop() # í‚¤ê°€ ì—†ìœ¼ë©´ ì•± ì‹¤í–‰ ì¤‘ì§€

st.title("ğŸ§  Aging and Health OECD ìë£Œ ê²€ìƒ‰ ë´‡")

# PDF íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
# ì±—ë´‡ì´ í•™ìŠµí•  PDF íŒŒì¼(.pdf)ì„ ì´ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.
# ì´ ê²½ë¡œëŠ” Streamlit ì•±ì´ ì‹¤í–‰ë˜ëŠ” ì„œë²„ í™˜ê²½ì˜ ê²½ë¡œì…ë‹ˆë‹¤.
TEXT_FOLDER = "/Users/yujin.sophia.kim/Desktop/Python/aiffel/LLM/Group_Project/OECD_Aging_Report" 

# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì €ì¥ë  í´ë”
DB_FOLDER = "./chroma_db_local_files_pdf" 

# CSV ë¶„ë¥˜ íŒŒì¼ ê²½ë¡œ ìë™ ê°ì§€
def find_csv_file():
    """CSV íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤."""
    possible_paths = [
        "./aging_health_classification.csv",  # í˜„ì¬ í´ë”
        "./data/aging_health_classification.csv",  # data í´ë”
        "/Users/choi/Desktop/programming/aiffel/Langchain-RAG/aging_health_classification.csv",  # ì ˆëŒ€ ê²½ë¡œ
        "/Users/choi/Desktop/programming/aiffel/Langchain-RAG/data/aging_health_classification.csv",  # data í´ë” ì ˆëŒ€ ê²½ë¡œ
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            st.sidebar.success(f"âœ… CSV íŒŒì¼ ë°œê²¬: {path}")
            return path
    
    st.sidebar.error("âŒ aging_health_classification.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    st.sidebar.info("ë‹¤ìŒ ìœ„ì¹˜ ì¤‘ í•˜ë‚˜ì— íŒŒì¼ì„ ë°°ì¹˜í•´ì£¼ì„¸ìš”:")
    for path in possible_paths:
        st.sidebar.write(f"- {path}")
    return None

CSV_CLASSIFICATION_PATH = find_csv_file()

# --- CSV ë¶„ë¥˜ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data
def load_classification_data():
    """
    CSV ë¶„ë¥˜ íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        df = pd.read_csv(CSV_CLASSIFICATION_PATH, encoding='utf-8')
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬ (ê³µë°± ì œê±°)
        df.columns = df.columns.str.strip()
        
        # ê²°ì¸¡ê°’ê³¼ ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
        df = df.fillna('')
        
        # ì—°ë„ ì»¬ëŸ¼ ì •ë¦¬ - ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ ë³€ê²½
        if 'ì—°ë„' in df.columns:
            df['ì—°ë„'] = df['ì—°ë„'].replace('', pd.NA)
        
        # ì£¼ì œ ì»¬ëŸ¼ì—ì„œ ë³µìˆ˜ ì£¼ì œ ë¶„ë¦¬ (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš°)
        topics_expanded = []
        if 'ì£¼ì œ' in df.columns:
            for _, row in df.iterrows():
                topics_str = str(row['ì£¼ì œ'])
                if topics_str and topics_str != '' and topics_str != 'nan':
                    # ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ ì£¼ì œë“¤ì„ ê°œë³„ í•­ëª©ìœ¼ë¡œ ì²˜ë¦¬
                    topics = [topic.strip() for topic in topics_str.split(',')]
                    for topic in topics:
                        if topic and topic != 'nan':  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                            topics_expanded.append(topic)

        # êµ­ê°€ ì»¬ëŸ¼ì—ì„œ ë³µìˆ˜ êµ­ê°€ ë¶„ë¦¬ (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš°)
        countries_expanded = []
        if 'êµ­ê°€' in df.columns:
            for _, row in df.iterrows():
                countries_str = str(row['êµ­ê°€'])
                if countries_str and countries_str != '' and countries_str != 'nan':
                    # ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ êµ­ê°€ë“¤ì„ ê°œë³„ í•­ëª©ìœ¼ë¡œ ì²˜ë¦¬
                    countries = [country.strip() for country in countries_str.split(',')]
                    for country in countries:
                        if country and country != 'nan':  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                            countries_expanded.append(country)
        
        return df, list(set(topics_expanded)), list(set(countries_expanded))  # ì¤‘ë³µ ì œê±°ëœ ê³ ìœ  ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    except Exception as e:
        st.error(f"CSV ë¶„ë¥˜ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(), [], []

# --- í•„í„°ë§ëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ ---
def get_filtered_files(df, selected_topics, selected_countries, selected_years):
    """
    ì„ íƒëœ í•„í„° ì¡°ê±´ì— ë”°ë¼ íŒŒì¼ ëª©ë¡ì„ í•„í„°ë§í•©ë‹ˆë‹¤.
    """
    if df.empty:
        return []
    
    filtered_df = df.copy()
    
    # ì£¼ì œ í•„í„°ë§ (ë³µìˆ˜ ì£¼ì œê°€ í¬í•¨ëœ ê²½ìš°ë„ ê³ ë ¤)
    if selected_topics and 'ì£¼ì œ' in df.columns:  # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        topic_mask = filtered_df['ì£¼ì œ'].apply(
            lambda x: any(topic in str(x) for topic in selected_topics) if pd.notna(x) else False
        )
        filtered_df = filtered_df[topic_mask]
    
    # êµ­ê°€ í•„í„°ë§ (ë³µìˆ˜ êµ­ê°€ê°€ í¬í•¨ëœ ê²½ìš°ë„ ê³ ë ¤)
    if selected_countries and 'êµ­ê°€' in df.columns:  # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        country_mask = filtered_df['êµ­ê°€'].apply(
            lambda x: any(country in str(x) for country in selected_countries) if pd.notna(x) else False
        )
        filtered_df = filtered_df[country_mask]
    
    # ì—°ë„ í•„í„°ë§ - ì•ˆì „í•œ ì—°ë„ ë¹„êµ
    if selected_years and 'ì—°ë„' in df.columns:  # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        def is_year_match(year_value, selected_years):
            """ì—°ë„ ê°’ì´ ì„ íƒëœ ì—°ë„ ëª©ë¡ì— í¬í•¨ë˜ëŠ”ì§€ ì•ˆì „í•˜ê²Œ í™•ì¸"""
            try:
                if pd.notna(year_value) and str(year_value).strip() != '':
                    year_str = str(int(float(year_value)))
                    return year_str in selected_years
                return False
            except (ValueError, TypeError):
                return False
        
        year_mask = filtered_df['ì—°ë„'].apply(lambda x: is_year_match(x, selected_years))
        filtered_df = filtered_df[year_mask]
    
    # íŒŒì¼ëª… ì»¬ëŸ¼ í™•ì¸ - ì—¬ëŸ¬ ê°€ëŠ¥ì„±ì„ ì²´í¬
    possible_filename_columns = ['íŒŒì¼ëª…', 'filename', 'file_name', 'íŒŒì¼ì´ë¦„', 'File', 'FileName']
    
    filename_column = None
    for col in possible_filename_columns:
        # ì •í™•í•œ ë§¤ì¹˜
        if col in df.columns:
            filename_column = col
            break
        # ê³µë°± ì œê±° í›„ ë§¤ì¹˜
        stripped_columns = [c.strip() for c in df.columns]
        if col in stripped_columns:
            # ì›ë³¸ ì»¬ëŸ¼ëª… ì°¾ê¸°
            for orig_col in df.columns:
                if orig_col.strip() == col:
                    filename_column = orig_col
                    break
            break
    
    if filename_column:
        return filtered_df[filename_column].tolist()
    else:
        # íŒŒì¼ëª… ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ëª¨ë“  ì»¬ëŸ¼ëª…ì„ ë³´ì—¬ì£¼ê³  ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ì‚¬ìš©
        st.sidebar.error("âŒ íŒŒì¼ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        st.sidebar.error(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
        
        if len(df.columns) > 0:
            first_col = df.columns[0]
            st.sidebar.warning(f"âš ï¸ ì²« ë²ˆì§¸ ì»¬ëŸ¼ '{first_col}'ì„ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return filtered_df[first_col].tolist()
        else:
            st.sidebar.error("CSV íŒŒì¼ì— ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            return []

# --- í´ë”ì—ì„œ íŒŒì¼ ì½ê¸° í•¨ìˆ˜ (í•„í„°ë§ ì ìš©) ---
def read_files_from_folder(folder_path, filtered_filenames=None, num_files=50): 
    """
    ì§€ì •ëœ í´ë”ì—ì„œ í•„í„°ë§ëœ íŒŒì¼ë“¤ë§Œ ì½ì–´ì™€ (íŒŒì¼ ê²½ë¡œ, íŒŒì¼ëª…) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        folder_path (str): íŒŒì¼ì„ ì½ì–´ì˜¬ í´ë”ì˜ ê²½ë¡œì…ë‹ˆë‹¤.
        filtered_filenames (list): í•„í„°ë§ëœ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  íŒŒì¼)
        num_files (int): ì½ì–´ì˜¬ ìµœëŒ€ íŒŒì¼ ê°œìˆ˜ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ 50ì…ë‹ˆë‹¤.
    """
    file_data_list = []
    
    if not os.path.isdir(folder_path):
        st.error(f"ì˜¤ë¥˜: '{folder_path}' ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        return file_data_list

    # í´ë” ë‚´ ëª¨ë“  PDF íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    all_files_in_folder = [
        f for f in os.listdir(folder_path) 
        if os.path.isfile(os.path.join(folder_path, f)) and f.lower().endswith('.pdf')
    ]
    
    # í•„í„°ë§ì´ ì ìš©ëœ ê²½ìš°, í•´ë‹¹ íŒŒì¼ë“¤ë§Œ ì„ íƒ
    if filtered_filenames is not None:
        files_to_process = [f for f in all_files_in_folder if f in filtered_filenames]
    else:
        files_to_process = all_files_in_folder
    
    # ì§€ì •ëœ ê°œìˆ˜ë§Œí¼ì˜ íŒŒì¼ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    files_to_read = files_to_process[:num_files]

    # ì„ íƒëœ ê° íŒŒì¼ì— ëŒ€í•´ ë°˜ë³µí•˜ì—¬ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    for filename_only in files_to_read:
        file_path = os.path.join(folder_path, filename_only)
        file_data_list.append((file_path, filename_only))
            
    return file_data_list

# --- PDF íŒŒì¼ ë¡œë“œ ë° Langchain Document ê°ì²´ë¡œ ë³€í™˜ í•¨ìˆ˜ (ìˆ˜ì •ë¨) ---
@st.cache_resource(show_spinner=False)
def load_and_prepare_documents(pdf_folder, openai_api_key, filtered_filenames=None):
    """
    ì§€ì •ëœ í´ë”ì—ì„œ í•„í„°ë§ëœ PDF íŒŒì¼ì„ ì½ì–´ì™€ Langchain Document ê°ì²´ë¡œ ë³€í™˜í•˜ê³ ,
    Chroma ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±/ë¡œë“œí•©ë‹ˆë‹¤.
    """
    # í•„í„°ë§ëœ íŒŒì¼ ê²½ë¡œë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ read_files_from_folder ì‚¬ìš©
    raw_files_data = read_files_from_folder(pdf_folder, filtered_filenames, num_files=50) 
    
    if not raw_files_data:
        st.warning("ì„ íƒëœ í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    docs = []
    for file_path, filename_only in raw_files_data:
        try:
            # extract_images ì˜µì…˜ì„ Falseë¡œ ë³€ê²½í•˜ì—¬ ì´ë¯¸ì§€ ì¶”ì¶œ ì˜¤ë¥˜ ë°©ì§€
            loader = PyPDFLoader(file_path, extract_images=False) 
            loaded_docs = loader.load()
            for doc in loaded_docs:
                doc.metadata["source"] = filename_only # ì›ë³¸ íŒŒì¼ëª…ì„ ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ê°€
            docs.extend(loaded_docs)
        except Exception as e:
            st.warning(f"ê²½ê³ : '{filename_only}' PDF íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
            
    if not docs:
        st.error("ì„ íƒëœ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # ë¬¸ì„œ ì²­í¬(ë¶„í• )
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = splitter.split_documents(docs)

    if not chunks:
        st.warning("ë¬¸ì„œ ì²­í¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë²¡í„° DBë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # í•„í„°ë§ì´ ì ìš©ëœ ê²½ìš° DB í´ë” ì´ë¦„ì— í•´ì‹œ ì¶”ê°€í•˜ì—¬ ìºì‹œ êµ¬ë¶„
    filter_hash = hash(str(sorted(filtered_filenames)) if filtered_filenames else "all_files")
    db_folder_with_filter = f"{DB_FOLDER}_{filter_hash}"
    
    # í˜„ì¬ ë¬¸ì„œë¡œ ìƒˆë¡œìš´ DB ìƒì„±ì„ ìœ„í•´ ê¸°ì¡´ DB í´ë” ì‚­ì œ
    if os.path.exists(db_folder_with_filter):
        st.info(f"ê¸°ì¡´ ë²¡í„° DBë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œìš´ DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        try:
            shutil.rmtree(db_folder_with_filter)
        except Exception as e:
            st.error(f"ê¸°ì¡´ DB í´ë”ë¥¼ ì‚­ì œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            return None, None

    try:
        # ì„ë² ë”© ìƒì„± ë° Chroma DBì— ì €ì¥
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        db = Chroma.from_documents(chunks, embeddings, persist_directory=db_folder_with_filter)
        db.persist() # DBë¥¼ ë””ìŠ¤í¬ì— ì €ì¥
        st.success(f"ìƒˆë¡œìš´ ë²¡í„° DBë¥¼ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤. (ì²˜ë¦¬ëœ íŒŒì¼: {len(raw_files_data)}ê°œ)")
        return docs, db
    except Exception as e:
        st.error(f"ë²¡í„° DB ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. OpenAI API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None

# CSV ë¶„ë¥˜ ë°ì´í„° ë¡œë“œ
if CSV_CLASSIFICATION_PATH and os.path.exists(CSV_CLASSIFICATION_PATH):
    classification_df, all_topics, all_countries = load_classification_data()
else:
    st.sidebar.error("ğŸ“ CSV ë¶„ë¥˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    uploaded_csv = st.sidebar.file_uploader(
        "CSV ë¶„ë¥˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", 
        type=['csv'],
        help="aging_health_classification.csv íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”"
    )
    
    if uploaded_csv is not None:
        # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥
        with open("temp_classification.csv", "wb") as f:
            f.write(uploaded_csv.getbuffer())
        CSV_CLASSIFICATION_PATH = "temp_classification.csv"
        classification_df, all_topics, all_countries = load_classification_data()
    else:
        classification_df, all_topics, all_countries = pd.DataFrame(), [], []

# ------------------ ì‚¬ì´ë“œë°” í¼ ë° í•„í„° -------------------
with st.sidebar:
    st.header("ğŸ“Š ìë£Œ í•„í„°ë§")
    
    # í•„í„° ì„¹ì…˜
    if not classification_df.empty:
        # ì£¼ì œ í•„í„° (ë©€í‹°ì…€ë ‰íŠ¸) - ê¸°ë³¸ê°’ ì œê±°
        if 'ì£¼ì œ' in classification_df.columns and all_topics:
            unique_topics = sorted(all_topics)  # ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            selected_topics = st.multiselect(
                "ğŸ¯ ì£¼ì œ ì„ íƒ", 
                options=unique_topics,
                default=[],  # ê¸°ë³¸ê°’ ì œê±°
                help="ì—¬ëŸ¬ ì£¼ì œë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        else:
            st.warning("CSV íŒŒì¼ì— 'ì£¼ì œ' ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            selected_topics = []
        
        # êµ­ê°€ í•„í„° (ë©€í‹°ì…€ë ‰íŠ¸) - ì£¼ì œì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
        if 'êµ­ê°€' in classification_df.columns and all_countries:
            unique_countries = sorted(all_countries)  # ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            selected_countries = st.multiselect(
                "ğŸŒ êµ­ê°€ ì„ íƒ",
                options=unique_countries,
                default=[],  # ê¸°ë³¸ê°’ ì œê±°
                help="ì—¬ëŸ¬ êµ­ê°€ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë³µìˆ˜ êµ­ê°€ ì§€ì›)"
            )
        else:
            st.warning("CSV íŒŒì¼ì— 'êµ­ê°€' ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            selected_countries = []
        
        # ì—°ë„ í•„í„° (ë©€í‹°ì…€ë ‰íŠ¸) - ë¹ˆ ê°’ê³¼ ë¬¸ìì—´ ì²˜ë¦¬ ê°œì„ 
        if 'ì—°ë„' in classification_df.columns:
            def safe_convert_year(year):
                """ì—°ë„ë¥¼ ì•ˆì „í•˜ê²Œ ì •ìˆ˜ë¡œ ë³€í™˜"""
                try:
                    if pd.notna(year) and str(year).strip() != '':
                        return int(float(year))  # floatì„ ê±°ì³ì„œ ë³€í™˜ (ì†Œìˆ˜ì  ìˆì„ ìˆ˜ ìˆìŒ)
                    return None
                except (ValueError, TypeError):
                    return None
            
            valid_years = []
            for year in classification_df['ì—°ë„'].unique():
                converted_year = safe_convert_year(year)
                if converted_year is not None:
                    valid_years.append(str(converted_year))
            
            unique_years = sorted(valid_years, reverse=True)  # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹ ë…„ë„ ë¨¼ì €)
            selected_years = st.multiselect(
                "ğŸ“… ì—°ë„ ì„ íƒ",
                options=unique_years,
                default=[],  # ê¸°ë³¸ê°’ ì œê±°
                help="íŠ¹ì • ì—°ë„ì˜ ìë£Œë¥¼ ì°¾ê³  ì‹¶ì„ ë•Œ ì„ íƒí•˜ì„¸ìš”."
            )
        else:
            st.warning("CSV íŒŒì¼ì— 'ì—°ë„' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            selected_years = []
        
        # ì–¸ì–´ í•„í„° ì œê±°ë¨
        
        # í•„í„° ì ìš© ê²°ê³¼ í‘œì‹œ
        filtered_files = get_filtered_files(classification_df, selected_topics, selected_countries, selected_years)
        
        # í•„í„°ê°€ í•˜ë‚˜ë„ ì„ íƒë˜ì§€ ì•Šì•˜ì„ ë•Œ ì•ˆë‚´ ë©”ì‹œì§€
        if not any([selected_topics, selected_countries, selected_years]):
            st.info("ğŸ” í•„í„°ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” íŒŒì¼ë“¤ì´ í‘œì‹œë©ë‹ˆë‹¤.")
            st.info(f"ğŸ“‚ ì „ì²´ íŒŒì¼ ìˆ˜: {len(classification_df)}ê°œ")
            filtered_files = []  # ì•„ë¬´ê²ƒë„ ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        else:
            st.info(f"ğŸ” í•„í„° ê²°ê³¼: {len(filtered_files)}ê°œ íŒŒì¼")
        
        # ì„ íƒëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ (ì ‘ê¸°/í¼ì¹˜ê¸°)
        with st.expander("ğŸ“‹ ì„ íƒëœ íŒŒì¼ ëª©ë¡ ë³´ê¸°"):
            if filtered_files:
                for i, filename in enumerate(filtered_files[:10], 1):  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
                    st.write(f"{i}. {filename}")
                if len(filtered_files) > 10:
                    st.write(f"... ì™¸ {len(filtered_files) - 10}ê°œ ë”")
            else:
                st.write("ì„ íƒëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("CSV ë¶„ë¥˜ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        filtered_files = None
        
    # ê°„ì†Œí™”ëœ ì •ì±… ë´‡ í¼ (ëª©ì ê³¼ ë‹¹ì‹ ì€ ëˆ„êµ¬ì¸ê°€ìš”ë§Œ ë‚¨ê¹€)
    with st.form("Againg and health ì •ì±… ë´‡"):
        st.subheader("ì´ˆê³ ë ¹ ì‹œëŒ€ ì •ì±… ê²€ìƒ‰ (Aging and Health)âœ¨")

        goal = st.text_area("ê²€ìƒ‰ ëª©ì ", placeholder="ì´ ê²€ìƒ‰ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?", key="sidebar_goal")
        method = st.selectbox("ë‹¹ì‹ ì€ ëˆ„êµ¬ì¸ê°€ìš”", ["ì •ì±…ì…ë²•ì", "í•™ê³„", "ì‹œë¯¼ë‹¨ì²´", "í–‰ì •ê°€", "ê¸°íƒ€"], key="sidebar_method")
        submitted = st.form_submit_button("âœï¸ ê´€ë ¨ ì •ì±… ì°¾ì•„ë³´ê¸°")

# --- ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ ---

# ì±„íŒ… ë©”ì‹œì§€ ê¸°ë¡ ì´ˆê¸°í™” (ì„¸ì…˜ ìƒíƒœì— ì €ì¥ë¨)
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "policy analyst", "content": "ğŸ’¡ì´ˆê³ ë ¹ ì‹œëŒ€ ë³´ê±´ë³µì§€ ì •ì±… ìˆ˜ë¦½ ìš°ë¦¬ ê°™ì´ ê³ ë¯¼í•´ ë´ìš”ğŸ’¡"}]

# ë¬¸ì„œ ë¡œë“œ ë° DB ì¤€ë¹„ (í•„í„°ë§ ì ìš©)
if not any([selected_topics, selected_countries, selected_years]):
    # í•„í„°ê°€ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°
    st.info("ğŸ’¡ ìœ„ì—ì„œ í•„í„°ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ë¬¸ì„œë“¤ë¡œë§Œ ì±—ë´‡ì´ í•™ìŠµë©ë‹ˆë‹¤!")
    documents, db = None, None
else:
    # í•„í„°ê°€ ì„ íƒëœ ê²½ìš°ì—ë§Œ ë¬¸ì„œ ë¡œë“œ
    with st.spinner(f"ì„ íƒëœ {len(filtered_files)}ê°œ PDF ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„° DB ì¤€ë¹„ ì¤‘..."):
        documents, db = load_and_prepare_documents(TEXT_FOLDER, openai_api_key, filtered_files)

# ê°„ì†Œí™”ëœ í”„ë¡œí¬ì ˆ ìƒì„± ë¡œì§ (ì‚¬ì´ë“œë°” í¼ ì œì¶œ ì‹œ íŠ¸ë¦¬ê±°ë¨)
if submitted and openai_api_key:
    if not all([goal, method]): 
        st.warning("ëª¨ë“  í•„ë“œë¥¼ ì±„ì›Œì£¼ì„¸ìš”!")
    else:
        with st.spinner("ì •ì±… ë¶„ì„ ì´ˆì•ˆ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤. ì±—ë´‡ì€ ë¸Œë ˆì¸ìŠ¤í† ë° ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•˜ì‹œê³  ì¶”ê°€ ì—°êµ¬ ì¡°ì‚¬ë¥¼ ì§ì ‘ ìˆ˜í–‰í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤."):
            system_prompt_for_proposal_generation = """
You are a senior health policy analyst, responding in a formal and professional tone. Your role is to analyze provided OECD health reports on aging and health, which have been stored in the database, in response to questions from policy makers, university professors, administrators, or citizens seeking consultation. When answering questions, prioritize information verified in the just uploaded documents only. If there are conflicts between documents, clearly state the most reliable source and briefly explain why it is considered more credible. When quoting, provide the exact sentence, the report name, and the page number.
If relevant information cannot be found in the provided reports, state clearly that there is insufficient information in the given context. If external searches are used, always disclose the source. Always aim to be helpful, concise, and directly answer the userâ€™s question. Respond in the language of the input (English or Korean).
You should always consider who the reader is (e.g., a policymaker, professor, administrator, or citizen) when providing your consultancy, and tailor your tone and level of detail accordingly.
"""
            # í•„í„° ì •ë³´ë„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            filter_info = f"""
ì„ íƒëœ í•„í„° ì¡°ê±´:
- ì£¼ì œ: {', '.join(selected_topics) if selected_topics else 'ì „ì²´'}
- êµ­ê°€: {', '.join(selected_countries) if selected_countries else 'ì „ì²´'}
- ì—°ë„: {', '.join(selected_years) if selected_years else 'ì „ì²´'}
- ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ìˆ˜: {len(filtered_files) if filtered_files else 0}ê°œ
"""
            
            user_prompt_for_proposal_generation = f"""
{filter_info}

ì—°êµ¬ ì„¤ì •:
- ê²€ìƒ‰ ëª©ì : {goal}
- ë‹¹ì‹ ì€ ëˆ„êµ¬ì¸ê°€ìš”: {method}
"""
            try:
                client_openai = OpenAI(api_key=openai_api_key)
                response = client_openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": system_prompt_for_proposal_generation},
                        {"role": "user", "content": user_prompt_for_proposal_generation}
                    ],
                    temperature=0.7
                )
                result = response.choices[0].message.content
                st.success("âœ… ì •ì±… ë¶„ì„ ì´ˆì•ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.markdown(result)

                st.session_state['current_proposal_context'] = {
                    "goal": goal, "method": method,
                    "full_text": result,
                    "filter_info": filter_info
                }

                st.download_button(
                    label="ë‹¤ìš´ë¡œë“œ (ì •ì±… ë¶„ì„ ì´ˆì•ˆ)",
                    data=result.encode('utf-8'),
                    file_name="ì •ì±…_ë¶„ì„_ì´ˆì•ˆ.txt",
                    mime="text/plain"
                )

            except Exception as e:
                st.error(f"âŒ ì •ì±… ë¶„ì„ ì´ˆì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# ì±„íŒ… ì…ë ¥ ë° ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # í•„í„°ê°€ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš° ì•ˆë‚´
    if not any([selected_topics, selected_countries, selected_years]):
        msg = "ğŸ” ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ í•„í„°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”! ì„ íƒí•œ ë¬¸ì„œë“¤ë¡œë§Œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        st.session_state.messages.append({"role": "policy analyst", "content": msg})
        st.chat_message("policy analyst").write(msg)
    elif not filtered_files:
        msg = "ğŸ˜… ì„ íƒí•œ í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ì„ ì„ íƒí•´ë³´ì„¸ìš”!"
        st.session_state.messages.append({"role": "policy analyst", "content": msg})
        st.chat_message("policy analyst").write(msg)
    elif openai_api_key and db:
        try:
            # ConversationalRetrievalChainì„ ìœ„í•œ ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
            msgs = StreamlitChatMessageHistory(key="chat_messages_history")
            memory = ConversationBufferMemory(memory_key="chat_history", chat_memory=msgs, return_messages=True, output_key="answer")

            # ê°„ì†Œí™”ëœ í”„ë¡œí¬ì ˆ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì±„íŒ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ê²°í•©
            chat_system_role_template_str = f"""
            ë‹¹ì‹ ì€ ê³ ë„ë¡œ ìˆ™ë ¨ë˜ê³  ì „ë¬¸í™”ëœ ì •ì±… ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì£¼ìš” ì—­í• ì€ ì œê³µëœ OECD ì •ì±… ë³´ê³ ì„œ(PDF ë¬¸ì„œ) ë° ìƒì„±ëœ ì •ì±… ë¶„ì„ ì´ˆì•ˆì„ ê¸°ë°˜ìœ¼ë¡œ ì •ë³´ì™€ í†µì°°ë ¥ì„ ì œê³µí•˜ì—¬ í•™ìƒë“¤ì˜ ì •ì±… ì—°êµ¬ë¥¼ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤.
            
            í˜„ì¬ ë¶„ì„ ëŒ€ìƒ ë¬¸ì„œ: {len(filtered_files)}ê°œ íŒŒì¼
            ì„ íƒëœ í•„í„°: ì£¼ì œ({len(selected_topics)}ê°œ), êµ­ê°€({len(selected_countries)}ê°œ), ì—°ë„({len(selected_years)}ê°œ)
            
            ì§ˆë¬¸ì— ë‹µë³€í•  ë•ŒëŠ” ì œê³µëœ ë¬¸ì„œë‚˜ í˜„ì¬ ì •ì±… ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ì˜ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
            ì œê³µëœ ë¬¸ì„œë‚˜ ë¶„ì„ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì¶©ë¶„í•œ ì •ë³´ê°€ ì—†ë‹¤ê³  ëª…ì‹œí•˜ì„¸ìš”.
            í•­ìƒ ë„ì›€ì´ ë˜ê³ , ê°„ê²°í•˜ë©°, ì§ˆë¬¸ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì„¸ìš”.
            """
            
            # í˜„ì¬ ì •ì±… ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            if 'current_proposal_context' in st.session_state and st.session_state['current_proposal_context']['full_text']:
                current_proposal_data = st.session_state['current_proposal_context']
                form_summary = (
                    f"í•™ìƒì˜ ì—°êµ¬ ì„¤ì •:\n"
                    f"- ê²€ìƒ‰ ëª©ì : {current_proposal_data.get('goal', 'N/A')}\n"
                    f"- ë‹¹ì‹ ì€ ëˆ„êµ¬ì¸ê°€ìš”: {current_proposal_data.get('method', 'N/A')}\n\n"
                    f"{current_proposal_data.get('filter_info', '')}\n"
                )
                full_proposal_text = current_proposal_data['full_text']
                
                chat_system_role_template_str += (
                    f"\n\ní˜„ì¬ í•™ìƒê³¼ ë…¼ì˜ ì¤‘ì¸ ì •ì±… ë¶„ì„ì˜ ì»¨í…ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n"
                    f"{form_summary}"
                    f"--- ìƒì„±ëœ ì •ì±… ë¶„ì„ ì´ˆì•ˆ ---\n"
                    f"{full_proposal_text}\n"
                    f"-------------------------------\n\n"
                )
            
            # ê²€ìƒ‰ëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ í¬í•¨í•˜ëŠ” ìµœì¢… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±
            final_qa_template = chat_system_role_template_str + """
ë‹¤ìŒì€ ê²€ìƒ‰ëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤:
{context}

ë‹¤ìŒì€ ì´ì „ ëŒ€í™” ê¸°ë¡ì…ë‹ˆë‹¤:
{chat_history}

ì§ˆë¬¸: {question}
ë‹µë³€:
"""
            
            # PromptTemplate ê°ì²´ë¡œ ë³€í™˜
            QA_CHAIN_PROMPT = PromptTemplate(
                input_variables=["context", "question", "chat_history"], 
                template=final_qa_template,
            )

            # ConversationalRetrievalChain ìƒì„±
            llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=openai_api_key)
            qa_chain = ConversationalRetrievalChain.from_llm(
                llm=llm,
                retriever=db.as_retriever(),
                memory=memory,
                return_source_documents=True,
                combine_docs_chain_kwargs={"prompt": QA_CHAIN_PROMPT},
                output_key="answer"
            )

            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                # ì‚¬ìš©ì ì§ˆë¬¸ìœ¼ë¡œ ì²´ì¸ í˜¸ì¶œ
                chat_response = qa_chain.invoke({"question": prompt, "chat_history": msgs.messages})
                msg = chat_response["answer"]

                # ì°¸ê³  ìë£Œ í‘œì‹œ
                if "source_documents" in chat_response and chat_response["source_documents"]:
                    unique_sources = {}
                    for doc in chat_response["source_documents"]:
                        source_filename = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼")
                        page_number = doc.metadata.get("page", None)
                        
                        if source_filename not in unique_sources:
                            unique_sources[source_filename] = set()
                        if page_number is not None:
                            unique_sources[source_filename].add(page_number)
                    
                    source_list = []
                    for filename, pages in unique_sources.items():
                        if pages:
                            sorted_pages = sorted(list(pages))
                            source_list.append(f"{filename} (í˜ì´ì§€: {', '.join(map(str, sorted_pages))})")
                        else:
                            source_list.append(filename)
                    
                    if source_list:
                        sources_text = "ì°¸ê³  ìë£Œ: " + "; ".join(source_list)
                        st.info(sources_text)
                    else:
                        st.info("ì°¸ê³  ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
        except Exception as e:
            msg = f"ì±„íŒ… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            print(f"ì±„íŒ… ì˜¤ë¥˜: {e}")
    else:
        msg = "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ PDF ë¬¸ì„œê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ì±„íŒ… ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    st.session_state.messages.append({"role": "policy analyst", "content": msg})
    st.chat_message("policy analyst").write(msg)